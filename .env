# Ollama Configuration
OLLAMA_URL=http://localhost:11434
# Pour 6GB RAM: qwen2.5:7b-instruct-q4_0 (~4.4GB), qwen2.5:7b-instruct-q4_K_M (~4.7GB)
# qwen-8b équivaut à qwen2.5:7b-instruct avec quantization q4
OLLAMA_MODEL=qwen2.5:7b-instruct-q4_0

# API Configuration
API_TIMEOUT=300
MAX_RETRIES=3
RETRY_DELAY=1

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60

# Memory Optimization
MAX_CONTEXT_LENGTH=4096
ENABLE_STREAMING=true
